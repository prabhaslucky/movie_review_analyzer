# -*- coding: utf-8 -*-
"""movie_review_analyzer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sdMwRLFtdBcRMWBeB_Wf2Pvt5azdTGJX
"""

!pip install pandas scikit-learn numpy torch transformers tqdm
!pip install datasets

!pip install -q pandas scikit-learn numpy torch transformers tqdm

import pandas as pd

# If you haven't uploaded yet: run this once, then choose your reviews.csv
from google.colab import files
uploaded = files.upload()  # choose reviews.csv

df = pd.read_csv("reviews.csv")
print(df.head())
print("Columns:", df.columns.tolist())

import re

# Map text labels to 0/1
# assuming values are "positive"/"negative"
df["label_num"] = df["label"].map({"positive": 1, "negative": 0})

def clean_text(text: str) -> str:
    text = str(text).lower()
    text = re.sub(r"<br\s*/?>", " ", text)          # remove HTML breaks
    text = re.sub(r"http\S+|www\S+", "", text)      # remove URLs
    text = re.sub(r"[^a-z0-9\s]", " ", text)        # keep letters/numbers/spaces
    text = re.sub(r"\s+", " ", text).strip()        # collapse spaces
    return text

df["clean_review"] = df["review"].apply(clean_text)

# Drop duplicates & missing
df = df.dropna(subset=["clean_review", "label_num"]).drop_duplicates(subset=["clean_review"])

print(df.head())
print(df["label_num"].value_counts())

from sklearn.model_selection import train_test_split

train_df, test_df = train_test_split(
    df,
    test_size=0.2,
    random_state=42,
    stratify=df["label_num"]
)

train_df, val_df = train_test_split(
    train_df,
    test_size=0.1,
    random_state=42,
    stratify=train_df["label_num"]
)

train_df.shape, val_df.shape, test_df.shape

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

# TF-IDF features
vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))

X_train_tf = vectorizer.fit_transform(train_df["clean_review"])
X_val_tf   = vectorizer.transform(val_df["clean_review"])
X_test_tf  = vectorizer.transform(test_df["clean_review"])

y_train = train_df["label_num"].values
y_val   = val_df["label_num"].values
y_test  = test_df["label_num"].values

baseline_clf = LogisticRegression(max_iter=1000)
baseline_clf.fit(X_train_tf, y_train)

print("Validation performance (TF-IDF baseline):")
val_preds = baseline_clf.predict(X_val_tf)
print(classification_report(y_val, val_preds))

print("Test performance (TF-IDF baseline):")
test_preds = baseline_clf.predict(X_test_tf)
print(classification_report(y_test, test_preds))

import torch
import numpy as np
from transformers import DistilBertTokenizerFast, DistilBertModel
from tqdm.auto import tqdm

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

tokenizer = DistilBertTokenizerFast.from_pretrained("distilbert-base-uncased")
bert_model = DistilBertModel.from_pretrained("distilbert-base-uncased").to(device)

def get_bert_embeddings(text_list):
    """
    Convert a list of texts into a numpy array of BERT [CLS] embeddings.
    """
    all_embeddings = []
    for text in tqdm(text_list):
        inputs = tokenizer(
            text,
            padding="max_length",
            truncation=True,
            max_length=128,
            return_tensors="pt"
        ).to(device)

        with torch.no_grad():
            outputs = bert_model(**inputs)
        # CLS token representation (first token)
        cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()
        all_embeddings.append(cls_embedding[0])

    return np.vstack(all_embeddings)

!pip install -q sentence-transformers

import torch
from sentence_transformers import SentenceTransformer

device = "cuda" if torch.cuda.is_available() else "cpu"
print("Using device:", device)

st_model = SentenceTransformer("all-MiniLM-L6-v2", device=device)

# Create embeddings using MiniLM (much faster)
X_train_bert = st_model.encode(
    train_df["clean_review"].tolist(),
    batch_size=128,
    show_progress_bar=True
)

X_val_bert = st_model.encode(
    val_df["clean_review"].tolist(),
    batch_size=128,
    show_progress_bar=True
)

X_test_bert = st_model.encode(
    test_df["clean_review"].tolist(),
    batch_size=128,
    show_progress_bar=True
)

y_train = train_df["label_num"].values
y_val   = val_df["label_num"].values
y_test  = test_df["label_num"].values

X_train_bert.shape, X_val_bert.shape, X_test_bert.shape

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

bert_clf = LogisticRegression(max_iter=2000)
bert_clf.fit(X_train_bert, y_train)

print("Validation performance (BERT embeddings):")
val_preds_bert = bert_clf.predict(X_val_bert)
print(classification_report(y_val, val_preds_bert))

print("Test performance (BERT embeddings):")
test_preds_bert = bert_clf.predict(X_test_bert)
print(classification_report(y_test, test_preds_bert))

import random

def summarize_review(text, pred_label):
    sentiment_word = "positive" if pred_label == 1 else "negative"
    return (
        f"This review expresses a {sentiment_word} opinion about the movie, "
        f"highlighting aspects related to its story, characters, and overall experience."
    )

# pick a random test review
sample = test_df.sample(1).iloc[0]
sample_text = sample["review"]
true_label = sample["label_num"]

# FIXED PREDICTION LINE â†“â†“â†“
pred_label = bert_clf.predict(st_model.encode([sample["clean_review"]]))[0]

print("Original review:\n", sample_text)
print("\nTrue sentiment:", "Positive" if true_label == 1 else "Negative")
print("Predicted sentiment:", "Positive" if pred_label == 1 else "Negative")
print("\nGenerated summary:")
print(summarize_review(sample_text, pred_label))

!pip install gradio

import gradio as gr

def predict_and_summarize(text):
    clean = clean_text(text)
    pred = bert_clf.predict(st_model.encode([clean]))[0]
    sentiment = "Positive" if pred == 1 else "Negative"
    return sentiment, summarize_review(text, pred)

demo = gr.Interface(fn=predict_and_summarize,
                    inputs="text",
                    outputs=["text", "text"],
                    title="ðŸŽ¬ Movie Review Sentiment Analyzer")

demo.launch()